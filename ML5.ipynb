{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdrNXruWXHcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0APPNZSXE_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_url = 'https://raw.githubusercontent.com/TatianaShavrina/hse_ml_m1/master/ensembles/complaints.csv'\n",
        "data = pd.read_csv(data_url, sep='\\t')\n",
        "y = data[\"PRODUCT_ID\"]\n",
        "X = data[\"cleaned_text\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSOtYfkmzGEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def normalize(data):\n",
        "  res = []\n",
        "  for item in data:\n",
        "    res.append(' '.join([x for x in item.split() if len(x) > 3]))\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdvVfFyY1N9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_norm = normalize(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPkkrTEhHrH",
        "colab_type": "text"
      },
      "source": [
        "# Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSicnr1P1w9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVfJLjn9CIMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def the_model(weights):\n",
        "  clf1 = LogisticRegression(multi_class='multinomial',\n",
        "                            solver='lbfgs',\n",
        "                            random_state=1,\n",
        "                            max_iter=300)\n",
        "  clf2 = ExtraTreesClassifier(n_estimators=50,\n",
        "                              random_state=1,\n",
        "                              criterion='entropy',\n",
        "                              max_depth=30,\n",
        "                              min_samples_split=3)\n",
        "  clf3 = GaussianNB()\n",
        "\n",
        "  clf4 = MultinomialNB(alpha=0.1, fit_prior=True)\n",
        "\n",
        "  clf5 = KNeighborsClassifier(n_neighbors=2) \n",
        "\n",
        "  eclf = VotingClassifier(\n",
        "          estimators=[('lr', clf1), \n",
        "                      ('etc', clf2), \n",
        "                      ('gnb', clf3), \n",
        "                      ('mnb', clf4),\n",
        "                      ('knc', clf5)], \n",
        "          voting='hard',\n",
        "          weights=weights)\n",
        "\n",
        "  voting = Pipeline([\n",
        "      ('vect', CountVectorizer(analyzer='word', max_features=450)),\n",
        "      ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "      ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\n",
        "      ('clf', eclf),\n",
        "      ])\n",
        "  voting = voting.fit(X_train, y_train)\n",
        "  predictions = voting.predict(X_test)\n",
        "  print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "  print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "  print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "  print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_jcgAP8G7bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e8de68a9-a538-4526-ac8d-68673299013c"
      },
      "source": [
        "the_model([1,2,1,1,1])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.74\n",
            "Recall:   0.72\n",
            "F1-measure:   0.72\n",
            "Accuracy:   0.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-KFCzAyHiUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz && gunzip cc.en.300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u70HRKZsfpz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMC75an21Vh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20560837-4442-4273-e62e-ee26bed6f696"
      },
      "source": [
        "import fasttext\n",
        "ft = fasttext.load_model('cc.en.300.bin')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66kqAzdCGNmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter,defaultdict\n",
        "def get_embedding(text, model, dim):\n",
        "    text = text.split()\n",
        "    words = Counter(text)\n",
        "    total = len(text)\n",
        "    vectors = np.zeros((len(words), dim))\n",
        "    \n",
        "    for i,word in enumerate(words):\n",
        "        try:\n",
        "            v = model[word]\n",
        "            vectors[i] = v*(words[word]/total) \n",
        "        except (KeyError, ValueError):\n",
        "            continue\n",
        "    \n",
        "    if vectors.any():\n",
        "        vector = np.average(vectors, axis=0)\n",
        "    else:\n",
        "        vector = np.zeros((dim))\n",
        "    \n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN3RmyEHF9Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim = 300\n",
        "X_ft = np.zeros((len(X_norm), dim))\n",
        "for i in range(len(X_norm)):\n",
        "    X_ft[i] = get_embedding(X_norm[i], ft, dim)\n",
        "\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_ft, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "075kmZ8BGZc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def the_model2(weights):\n",
        "  clf1 = LogisticRegression(multi_class='multinomial',\n",
        "                            solver='lbfgs',\n",
        "                            random_state=1,\n",
        "                            max_iter=300)\n",
        "  clf2 = ExtraTreesClassifier(n_estimators=50,\n",
        "                              random_state=1,\n",
        "                              criterion='entropy',\n",
        "                              max_depth=30,\n",
        "                              min_samples_split=3)\n",
        "  clf3 = GaussianNB()\n",
        "\n",
        "  clf4 = KNeighborsClassifier(n_neighbors=2) \n",
        "\n",
        "  eclf = VotingClassifier(\n",
        "          estimators=[('lr', clf1), \n",
        "                      ('etc', clf2), \n",
        "                      ('gnb', clf3), \n",
        "                      ('knc', clf4)], \n",
        "          voting='hard',\n",
        "          weights=weights)\n",
        "\n",
        "  voting = Pipeline([\n",
        "      # ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\n",
        "      ('clf', eclf),\n",
        "      ])\n",
        "  voting = voting.fit(X_train_2, y_train_2)\n",
        "  predictions = voting.predict(X_test_2)\n",
        "  print(\"Precision: {0:6.2f}\".format(precision_score(y_test_2, predictions, average='macro')))\n",
        "  print(\"Recall: {0:6.2f}\".format(recall_score(y_test_2, predictions, average='macro')))\n",
        "  print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test_2, predictions, average='macro')))\n",
        "  print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test_2, predictions)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9HdGxLdL2ro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5bdf1ad3-398d-4498-c335-0c3ca70f84db"
      },
      "source": [
        "the_model2([1,1,1,1])"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.50\n",
            "Recall:   0.42\n",
            "F1-measure:   0.37\n",
            "Accuracy:   0.43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK5SYsB6hQGr",
        "colab_type": "text"
      },
      "source": [
        "# Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB-mJcsiL3I_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "def the_model3(base_clf):\n",
        "  clf = BaggingClassifier(base_estimator=base_clf,\n",
        "                          n_estimators=20,\n",
        "                          max_samples=0.7,\n",
        "                          max_features=0.8,\n",
        "                          bootstrap=False,\n",
        "                          bootstrap_features=False)\n",
        "\n",
        "  pipeline = Pipeline([\n",
        "      ('vect', CountVectorizer(analyzer='word', max_features=450)),\n",
        "      ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "      ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\n",
        "      ('clf', clf),\n",
        "      ])\n",
        "  voting = pipeline.fit(X_train, y_train)\n",
        "  predictions = pipeline.predict(X_test)\n",
        "  print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "  print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "  print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "  print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXV08hTxoQGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "211a5632-f55d-4398-e4af-616c714cb9c7"
      },
      "source": [
        "clfs = [LogisticRegression(multi_class='multinomial',\n",
        "                          solver='lbfgs',\n",
        "                          random_state=1,\n",
        "                          max_iter=300),\n",
        "        ExtraTreesClassifier(n_estimators=50,\n",
        "                            random_state=1,\n",
        "                            criterion='entropy',\n",
        "                            max_depth=30,\n",
        "                            min_samples_split=3),\n",
        "        GaussianNB(),\n",
        "        MultinomialNB(alpha=0.1, fit_prior=True),\n",
        "        KNeighborsClassifier(n_neighbors=2)]\n",
        "\n",
        "for clf in clfs:\n",
        "  the_model3(clf)\n",
        "  print()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.68\n",
            "Recall:   0.68\n",
            "F1-measure:   0.68\n",
            "Accuracy:   0.68\n",
            "\n",
            "Precision:   0.74\n",
            "Recall:   0.73\n",
            "F1-measure:   0.73\n",
            "Accuracy:   0.73\n",
            "\n",
            "Precision:   0.61\n",
            "Recall:   0.61\n",
            "F1-measure:   0.60\n",
            "Accuracy:   0.61\n",
            "\n",
            "Precision:   0.67\n",
            "Recall:   0.66\n",
            "F1-measure:   0.66\n",
            "Accuracy:   0.66\n",
            "\n",
            "Precision:   0.66\n",
            "Recall:   0.63\n",
            "F1-measure:   0.63\n",
            "Accuracy:   0.63\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k_YtQDPhSya",
        "colab_type": "text"
      },
      "source": [
        "# Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG8nKcBdhbp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "def the_model4(base_clf):\n",
        "  clf = AdaBoostClassifier(base_estimator=base_clf, n_estimators=20)\n",
        "\n",
        "  pipeline = Pipeline([\n",
        "      ('vect', CountVectorizer(analyzer='word', max_features=450)),\n",
        "      ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
        "      ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\n",
        "      ('clf', clf),\n",
        "      ])\n",
        "  voting = pipeline.fit(X_train, y_train)\n",
        "  predictions = pipeline.predict(X_test)\n",
        "  print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
        "  print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
        "  print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
        "  print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgZvnxrBq5Fz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "3239ef6e-1a65-445d-ba9e-c3f3b2390d1f"
      },
      "source": [
        "clfs = [LogisticRegression(multi_class='multinomial',\n",
        "                          solver='lbfgs',\n",
        "                          random_state=1,\n",
        "                          max_iter=300),\n",
        "        ExtraTreesClassifier(n_estimators=50,\n",
        "                            random_state=1,\n",
        "                            criterion='entropy',\n",
        "                            max_depth=30,\n",
        "                            min_samples_split=3),\n",
        "        GaussianNB(),\n",
        "        MultinomialNB(alpha=0.1, fit_prior=True),\n",
        "        DecisionTreeClassifier(criterion='entropy', max_depth=1)]\n",
        "\n",
        "for clf in clfs:\n",
        "  the_model4(clf)\n",
        "  print()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision:   0.70\n",
            "Recall:   0.54\n",
            "F1-measure:   0.50\n",
            "Accuracy:   0.55\n",
            "\n",
            "Precision:   0.72\n",
            "Recall:   0.71\n",
            "F1-measure:   0.71\n",
            "Accuracy:   0.71\n",
            "\n",
            "Precision:   0.46\n",
            "Recall:   0.44\n",
            "F1-measure:   0.43\n",
            "Accuracy:   0.43\n",
            "\n",
            "Precision:   0.66\n",
            "Recall:   0.64\n",
            "F1-measure:   0.65\n",
            "Accuracy:   0.64\n",
            "\n",
            "Precision:   0.61\n",
            "Recall:   0.60\n",
            "F1-measure:   0.60\n",
            "Accuracy:   0.60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}